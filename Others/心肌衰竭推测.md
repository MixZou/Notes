# 从体表ECG信号处理推断心肌舒张异常

>  **原文：Prediction of Abnormal Myocardial Relaxation From Signal Processed Surface ECG**

## 体表ECG信号处理中，心肌舒张异常情况推测

- 大多数LVDD（左心室舒张末期）患者都伴随着心肌舒张功能受损，这是心血管以及全死因死亡强有力的推测要素
- 本文以signal processed ECG简称spECG作为心肌舒张异常表现的推测工具
- 通过门诊病人冠状动脉的CT和超声心动图作为对左心室舒张末期的评估，使用机器学习验证spECG对心肌舒张异常的推测

### 心力衰竭的临床表现阶段

一般有四个阶段

A：无心脏结构或功能改变的危险因素

B：患者目前或者以前没有心力衰竭的症状，但有结构性心脏病。大部分患者有糖尿病或者高血压；LVDD患者中几乎所有心脏结构和功能改变的异常都能轻易地被超声心动图识别到。但是费用昂贵，且不建议阶段A/B无症状患者选择

### 原理与目的

- 正向t波代表左室基底到心尖和复极从心外膜到心内膜的跨壁进展对正常的左室机械松弛至关重要

- 心电的微妙变化也是导致心肌松弛异常的主要原因，但是ECG无法轻易地识别出来

- SpECG可以通过机器学习来提取特殊的心电频谱模式，更加有效地检测到早期LVDD

### 方法

该研究评估spECG检测可能患病人群中LVDD患病率的效用

1. 随机招募了200名门诊患者，在同一次实验中进行冠状动脉CT检测、12导联心电图检测，和二维超声心动图（包括组织多普勒）检查

2. 排除患有心律失常、不稳定心绞痛，有心脏手术史，起搏器或者胸部畸形和二尖瓣严重坏死无法确认二尖瓣环速度的受试者。

2. 剩下188位的临床患者，CT，ECG以及转化ECG数据。并且通过一组性别匹配，无已知心脏疾病，心电图与心电图评估正常的个体来验证正常的复极模式。

#### 临床特征

收集了研究对象们的临床特征：人口统计学特征，合并症(并存疾病)，药物治疗，体重指数与实验室数据(包括血清钾和肾功能)

- 高血压：收缩压大于140 mm Hg，舒张压大于90 mm Hg
- 糖尿病：有糖尿病病史，口服降糖药或胰岛素治疗
-  CAD：冠状动脉CT血管造影，动脉狭窄大于50%，存在心肌梗塞病史
- BMI：数值超过肥胖标准

#### spECG

根据明尼苏达州代码手册，该软件使用定量描述自动对心电图异常进行分类

研究对象均接受12导联体表心电图记录；定量描述包括平均心率；P，QRS波；T轴；P和QRS持续时间；PR和QT间隔；和矫正的QT(QTc)间隔;

**信号处理采用连续小波变换**数学,与傅里叶分析相似。这一处理过程将心电信号转换成一种归一化(normalized)的能量分布，其**频率显示在y轴上，3到200Hz。时间轴x心肌能量为彩色谱(颜色范围0-255)，蓝色表示最低，红色最高**

连续小波变换与传统的心电信号进行时间校对，用于计算多指标。

例如，在t波峰值之前一个预定义的时间段内，选择所有频率的MyoVista颜色波形(归一化、无符号连续小波变换)的最大值。这个值称为心室早期测量指数(VIEM)。同样，在t波峰值后的一个预定义时间段内，也选择了MyoVista彩色波形在所有频率上的最大值。这个值被称为心室指数晚期测量(ventricular index late measure)。

MyoVista能量算法（称为Icon）还将患者分为三类能量（考虑到性别和年龄等因素），其中3级能量最低，而1级能量最高

#### 超声心动图

通过对比和实验，使用**随机森林分类和蒙特卡洛交叉验证**的组合模型得到的误识率更小，更稳定。

进行总共20次迭代，每次迭代将67%样本作为训练集，33%作为子集。多次迭代是为了让每个研究对象在累计测试集中至少出现2次。

在随机森林的20次迭代中，对low $e’$的预测概率、变量重要性以及包外(out-of-bag)错误率进行汇总和平均。

通过超声心动图得到舒张初期(early diastolic wave velocity)和收缩末期(late diastolic atrial contraction wave velocity)的波速：E和A；e'(early diastolic relaxation velocity)是舒张早期的舒张速度；

而E/e'和和E/A的比值为左心室充盈压的估计值.并且以下是异常的临界值

$e'$异常：隔膜$eʹ$速度<7 cm/s，或侧壁$e'$速度<10 cm/s；

$E/e'$异常：从隔膜和侧壁的$E/e'$平均值> 14；

TR（tricuspid regurgitation）是三尖瓣反流速度异常：> 2.8 m / s；

左心房容积指数异常：LV > 34 ml/m²。  

### 基于机器学习的分类

1. 选择合适的分类器组合与样本分割的方法；使用R package 染色体陈列分析[^1]，直接对比8个不同的分类器（逐级提升，对角判别分析，偏最小二乘线性判别分析，收缩判别分析，前馈神经网络，概率神经网络，随机森林，支持向量机）和使用固定随机种子三种样本分割的方法（十折交叉验证，蒙特卡洛交叉验证，和自抽样（bootsrapping）[^2] ）

2. 对每一种组合都估计其误识率，布莱尔分数[^3]（brier scores），以及low e‘的平均概率。使用这些参数，让我们的分类器与分割方法更能捕捉到数据的结构。

3. 使用随机森林集成分类器和蒙特卡洛交叉验证程序对研究对象进行分类。

4. 随机森林分类器：输入数量370；输出类型为[二分类](https://www.cnblogs.com/MrPan/p/9495136.html)；每个节点上可用于分割的变量有19个，最小的节点有5个；错误率从the out-of-bag trees估计的。使用基于置换的指标来衡量变量重要性，该指标捕获了可归因于给定变量的预测的平均改进。

5. 对模型进行了总共20次迭代，每次迭代将样本分为一个训练（67％）和一个测试（33％）子集。多次迭代旨在累积测试子集中每个研究参与者的至少2次出现。在随机森林的20次迭代中，对low e’的预测概率、变量重要性以及包外(out-of-bag)错误率进行汇总和平均。

### 统计分析

使用Kolmogorov-SMIRNOV检验检验正态分布后，使用Pearson卡方检验（拟合优度）或Fisher精确检验（分类变量）和Student t检验（连续变量）进行组间比较

通过估计接收器工作特性曲线下的面积来评估预测准确性和筛选性能

使用Cochran's Q检验评估了缓和变量类别下曲线下面积的异质性，评估了临床和ECG协变量的潜在缓和剂作用对预测准确性的差异

使用增量判别度改进和净重分类指数的连续版本确定基于随机森林的分类器相对于其他low $e'$的临床预测指标的增量值。用Stata 14.0 做所有数据分析，用到的软件包IDI。统计学显着性在整体I型错误率为0.05时进行了测试。

## 结果

188位研究对象的临床特征展示于table1中。在研究样本中low $e’$的患病率为70%，且年龄60及以上，肥胖，高血压，ct证实冠状动脉狭窄的人群检测到low e‘的风险明显更高。在low $e’$状态下，有几个并存的超声心动图特征，包括左心室壁厚度，向心性重构或肥大，以及许多临床上用于定义DD(舒张功能障碍)的变量

### 基于随机森林分类的spECG预测表现

- 使用8个基于spECG 370个特征来识别low $e’$ 的ML分类器，随机森林分类和蒙特卡洛交叉验证分割策略提供了稳定且低的错误率。
- 使用基于森林的随机分类器预测低e'的曲线下面积为91％（95％置信区间[CI]：86％至95％），灵敏度和特异性分别为80％和84％ 
- Janiza测试表明，总计257个特征（在线补充数据文件中详细描述了370个）非常重要
- 前25个特征显示在图3A。在构建分类器中最重要的变量是ICON，它代表导出的能量测量值，可捕获心肌能量动力学的整体类别
- 详细分析表明，仅ICON变量在预测low e’时具有显着的独立性和累加性使用。ICON的分布不是特定于年龄和人群的

### 基于随机森林分类spECG的预测假定的适度

调查了临床与ECG协变量可能影响到基于随机森林分类的spECG的预测性能是否重要

研究结果表明：对六十岁及以上年龄的肥胖、高血压的个体展现出的性能表现更好

同样，在格拉斯哥解释性分析中处在“边界”或“异常”的个人与随机森林分类器对low $e’$的较好预测相关联

然而，这种梯度在心电图诊断标准中并没有统计学上的异质性，没有其它变量(包括CT确诊的动脉狭窄)在统计学上有显著的调节效应

### 用假定适度的增量值来检测 low $e'$

确定基于随机森林分类器的low $e’$预测值的添加是否具有高于和年龄≥60岁，肥胖，高血压，这三个关于low $e’$风险的临床特征的增量值。

确定基于随机森林分类器的low $e’$预测的添加是否具有与low $e’$’高风险，年龄≥60岁，肥胖和高血压相关的三个临床特征之上和之外的增量值

我们发现，由于分类器的使用，预测能力有了显著提高，曲线下面积提高了19% (p <0.001)，综合辨别指数提高了0.42 (p <0.001)，并且对超过80%的low $e’$和正常个体进行了正确的重新分类(p <0.001)

此外，在模型中加入表面心电图的格拉斯哥风险分类后，基于spECG的随机森林分类器继续显著改善曲线下面积(提高16%)、综合识别指数(提高0.40)和重分类(正确重分类超过80%的个体)(表4，模型2)

## 讨论

普通人群中LVDD患病率高，但是体检无法可靠地检查到左心室功能障碍，且如果是普通的ECG，需要医生非常有经验和明锐才能确诊这些本需要通过超声心动图检验的患者们

尽管ECG被广泛用于评估心血管功能的技术程序，但没有单一或明确的ECG模式可预测LVDD的存在。我们将小波变换ECG的测量结果与ML技术相结合，以提取时频指数和信号spECG的特征。首要目的是开发一种自动诊断心肌松弛异常的算法

机器学习的方法有助于避免繁琐的任务，也就是从小波变换的ECG信号中去手动识别特征，也就是关于舒张功能障碍的重要信息

spECG展现了与超声心动图同样可靠的预测性能。此外，对异常松弛的预测也能使较晚期的DD和并发CAD的受试者更容易识别，与临床变量和体表心电图相比，增加值明显更高

利用QRS波峰值的小波能量来衡量t波显示中能量的出现，这种能量颜色的相对分布提高了信噪比，放大了复极能量信号，从而可以提取与早期舒张心肌舒张速度降低相关的特征。在表面心电图上观察到的T波波峰与波峰末端之间的时间间隔与组织多普勒衍生的早期舒张压LV纵向心肌舒张速度之间呈反线性关系。另一项研究使用无监督机器学习将保留射血分数的心力衰竭分为3种具有不同风险特征的表型。在所有这些研究中，相关性均中等，并且ECG指标作为诊断测试并不可靠，这很可能是由于仅使用1个ECG功能的简化

因此，我们选择了一种使用机器学习的多特征提取方法，以评估spECG预测本来计划接受CT冠状动脉造影检查的具有危险因素的患者的异常心肌松弛能力

### 研究局限

这是针对少数患者的可行性研究。确定了该数据集的事后统计能力，以检测由于使用pROC R软件包将随机森林分类器包含到判别模型中而导致的曲线下面积的观察到的差异。分析显示，模型1和模型2的事后统计功效分别为0.9788和0.9562（表3）。这些数据加上基于RF的分类器的知识在一定程度上消除了进行多次比较的需要，因为它表明了这些比较估计值具有足够的统计能力来解决研究问题。

在更简单的预测变量（例如，仅基于在线表3中所示的ICON变量）或更全面的模型（例如本研究中使用的模型）之间的权衡仍有待将来的研究进行评估

敏感性和特异性分别为80％和84％，假阳性或阴性结果的原因可能与相对固定的eʹ异常定义有关，而没有针对eʹ的年龄和性别相关变化进行临床调整

随着时间的推移，小波变换分析已应用于各种可预测精度的生物医学信号。但是，LVDD的评估是一项新的应用，在连续访问期间随着时间的可重复性将需要在未来的调查中进行评估

评估了使用spECG来检测左室舒张功能异常，这是指舒张功能障碍的早期阶段，其中许多患者可能尚无晚期特征，包括左心房增大和左心房升高以及左室充盈压。需要进一步的研究来了解spECG在预测LVDD进行性分级中的价值。同样，调查spECG在评估LV应变异常中的作用也很有价值，LV异常是心脏功能障碍更敏感的标志

本研究未解决spECG诊断性能的病因特异性差异，这将需要将来的深入探索

### 总结

心电图仍然是心脏病学中广泛使用的诊断筛查测试程序之一。 

尽管LVDD发生在心血管疾病的早期，但仍未认识到使用ECG作为检测LVDD的筛查技术

 本研究使用信号处理技术放大了与心肌松弛异常的发展相关的表面心电图频谱的微小变化，并显示了与常规心电图相比，spECG的增量值，可用于可靠地预测心肌松弛异常

 这些数据表明spECG作为LVDD的新型筛选机制具有潜在作用，该机制可用于基于人群的研究中，以识别将从超声心动图评估中受益的患者

## 名词解释

- A = late diastolic filling(atrial contraction wave) velocity

-  BMI = body mass index

-  CAD = coronary artery disease

-  CT = computed tomography

-  E = peak early filling(diastolic wave) velocity

-  $e’$ = early diastolic relaxation velocity

- ECG = electrocardiogram

- LVDD = left ventricular diastolic dysfuction

-  ML = machine learning

- spECG = signal-processed surface electrocardiography

- Base to apex：基底段至心尖段
- Comorbidity：合并症；最好译成并存疾病。合并症不一定有明确的因果关系，如高血压、糖尿病、高脂血症都可以合并冠心病或脑卒中，但究竟是那一种病因（或两种以上）要具体分析。合并症在发生时间上比并发症长，如糖尿病人长时间血糖控制不佳，就易合并白内障

**蒙特卡洛交叉验证（Monte Carlo Cross Validation）**

即将留出法（holdout）进行多次。每次将数据集随机划分为训练集和验证集，这样进行多次单独的模型训练和验证，最后将这些验证结果取平均值，作为此模型的验证误差。与单次验证（holdout）相比，这种方法可以更好地衡量模型的性能。与K折交叉验证相比，这种方法能够更好地控制模型训练和验证的次数，以及训练集和验证集的比例。缺点是有些观测值可能从未被选入验证子样本，而有些观测值可能不止一次被选中。（偏差大，方差小）

总结：在数据较少的情况下，使用K折交叉验证来对模型进行评估是一个不错的选择。如果数据特别少，那么可以考虑用留一法。当数据较多时，使用留出法则非常合适。如果我们需要更精确一些的结果，则可以使用蒙特卡洛交叉验证。 

此外，需要特别注意的是：如果我们要对数据进行归一化处理或进行特征选择，应该在交叉验证的循环过程中执行这些操作，而不是在划分数据之前就将这些步骤应用到整个数据集。

 上面说的是对单个模型进行的交叉验证。如果要在多个不同设置的模型中进行选择，那么步骤和验证类似：首先将数据集划分为训练集和测试集，然后用交叉验证方法划分训练集（划分为训练集和验证集），训练出不同模型后，按验证集误差选出其中最好的模型，记录最好模型的各项设置，然后据此再用（训练集+验证集）数据训练出一个新模型，作为最终的模型，最后用测试集评估最终的模型。

可以看出，在上述模型评估和模型选择过程中，除了对模型进行评估之外，验证和交叉验证还有另外一个作用，就是对超参数进行优化。之前我们所说的根据情况不断调整模型就是其中一种超参数优化方式，叫做试错。另外一种超参数优化方式是：列出各种不同超参数设置的算法；使用验证或交叉验证方法在训练数据上训练出这些不同的模型，然后对这些模型在验证集上的性能进行评估；之后选择其中最好的模型对应的超参数设置。这种超参数优化方式称为网格搜索，当然还有其他的超参数优化方式。

对于超参数优化，推荐用10折交叉验证。



# 译者总结与遇到的问题

## 流程

```mermaid
graph LR
A[获取12导连ECG]--连续小波变换信号处理-->B[得到spECG图像]
B--输入/提取特征数据-->C[随机森林分类器]
C--数据集-->D[蒙特卡洛交叉验证]
D-->E[计算出预测性能]
F[获得超声心动图数据]--计算low e'/检查数据是否异常-->G[判断是否患病]
G--评估对比-->D
```

## 困难

1. 输入的ECG图像是什么样子的
2. 从医院拿到的数据没有横纵坐标
3. ECG如何处理成spECG，虽然论文中提到了morlet小波变换，但是还未找到方法实现

## 项目搁置原因

联系了原作者，他们已经把ECG转换成spECG做出了产品，且在医院投入使用.

------



[^1]:有组织缺陷人群的病因学检测，对染色体微缺失，微重复综合征有诊断优势
[^2]:“直观上就是：在已知数据的基础上, 通过用计算机来模拟N趋近于无穷大时候的情况, 把已知的DATA不断的重新SAMPLING, 从而在新的数据中得出原始数据的信息。再说的更简单更直观就是： 就是给你100个数据, 但是你觉得100个数据没办法真实反映样本的全貌, 你就把这100个数据重新随机的SAMPLE1000次, 这样你就有了100*1000个数据点了. 你的样本量就会增大很多。”Bootstrap的思想，是生成一系列bootstrap伪样本，每个样本是初始数据有放回抽样。通过对伪样本的计算，获得统计量的分布。例如，要进行1000次bootstrap，求平均值的置信区间 ，可以对每个伪样本计算平均值。这样就获得了1000个平均值。对着1000个平均值的分位数进行计算， 即可获得置信区间。已经证明，在初始样本足够大的情况下，bootstrap抽样能够无偏得接近总体的分布。
[^3]:衡量概率矫正的一个参数，Brier分数可以被认为是对一组概率预测的“校准”的量度，或者称为“ 成本函数 ”，这一组概率对应的情况必须互斥，并且概率之和必须为1。Brier分数对于一组预测值越低，预测校准越好。

